#!/bin/env python3

from typing import Annotated
from fastapi import FastAPI, File
import uvicorn

from io import BytesIO
from funasr import AutoModel
from funasr.utils.postprocess_utils import rich_transcription_postprocess
from pydub import AudioSegment

model_dir = "iic/SenseVoiceSmall"

# init model
model = AutoModel(
    model=model_dir,
    trust_remote_code=True,
    remote_code="./model.py",
    vad_model="fsmn-vad",
    vad_kwargs={"max_single_segment_time": 30000},
    device="cuda:0",
)

# generate code
def toText(audios):
    res = model.generate(
        input=audios,
        cache={},
        language="zh",  # "zh", "en", "yue", "ja", "ko", "nospeech"
        use_itn=True,
        batch_size_s=60,
        merge_vad=True,  #
        merge_length_s=15,
        disable_update=True
    )
    return rich_transcription_postprocess(res[0]["text"])

# start serve
app = FastAPI()

# health check
@app.get("/ping")
def ping():
    return {"status": 200}

# get file and handle it
@app.post("/invocations")
def invocations(file: Annotated[bytes, File()]):
    file_io = BytesIO(file)
    audio_segment = AudioSegment.from_file(file_io, format="mp3")
    audio_segment.export("./tmpfile.wav", format="wav")
    file_io.close()

    text = toText("./tmpfile.wav")
    resp = {"text": text}
    return resp

if __name__ == '__main__':
    uvicorn.run(app, host="0.0.0.0", port=8080)